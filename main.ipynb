{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom ChatBot using RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to develop a chatbot utilizing the Retrieval-Augmented Generation (RAG) method, leveraging a custom dataset built from a PDF containing my CV information. The chatbot will be designed to answer questions specifically related to my educational background, providing accurate and context-aware responses. This approach integrates document retrieval with language generation to enhance the chatbot’s ability to understand and deliver relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of my personal information, which is only available on my CV and is not part of the OpenAI model’s pretraining data. This makes the dataset appropriate because it ensures that the model is working with new, unseen information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "# Path to your PDF file\n",
    "pdf_file = r\"C:\\Users\\alsot\\Downloads\\CV_TAUA.pdf\"\n",
    "\n",
    "# Open the PDF file\n",
    "with open(pdf_file, \"rb\") as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    \n",
    "    # Extract text from each page\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "# Reconstruct paragraphs\n",
    "paragraphs = []\n",
    "current_paragraph = \"\"\n",
    "\n",
    "# Split the text into lines\n",
    "lines = text.replace(\"\\n\",\"\").split(\".\")\n",
    "\n",
    "lines_trim = [line.strip() for line in lines]\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(lines, columns=[\"text\"])\n",
    "df = df[~df[\"text\"].str.strip().eq(\"\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load credentials and create embeddings from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "openai.api_base = config[\"api_base\"]\n",
    "openai.api_key = config[\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the cosine distance between embeddings from CV and the created question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tauã Santos is a dedicated Mechanical Engineer...</td>\n",
       "      <td>[-0.02590862289071083, -0.0033735898323357105,...</td>\n",
       "      <td>0.150094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Beyond his professional experience, Tauã has ...</td>\n",
       "      <td>[-0.002841450972482562, -0.017338581383228302,...</td>\n",
       "      <td>0.156450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Beyond his technical skills, Tauã believes in...</td>\n",
       "      <td>[-0.008455007337033749, -0.008434616960585117,...</td>\n",
       "      <td>0.162055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tauã is passionate about using technology to ...</td>\n",
       "      <td>[-0.015827035531401634, -0.005707507487386465,...</td>\n",
       "      <td>0.162765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Throughout his career, Tauã has maintained a ...</td>\n",
       "      <td>[-0.02318953350186348, -0.011980372481048107, ...</td>\n",
       "      <td>0.163264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Tauã Santos is a dedicated Mechanical Engineer...   \n",
       "17   Beyond his professional experience, Tauã has ...   \n",
       "35   Beyond his technical skills, Tauã believes in...   \n",
       "29   Tauã is passionate about using technology to ...   \n",
       "25   Throughout his career, Tauã has maintained a ...   \n",
       "\n",
       "                                           embeddings  distances  \n",
       "0   [-0.02590862289071083, -0.0033735898323357105,...   0.150094  \n",
       "17  [-0.002841450972482562, -0.017338581383228302,...   0.156450  \n",
       "35  [-0.008455007337033749, -0.008434616960585117,...   0.162055  \n",
       "29  [-0.015827035531401634, -0.005707507487386465,...   0.162765  \n",
       "25  [-0.02318953350186348, -0.011980372481048107, ...   0.163264  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rows_sorted_by_relevance(\"Who is Tauã?\", df).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing the Previously Created Function to Retrieve the Most Relevant Context from Stored Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context:  :\n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I don't know\"\n",
      "\n",
      "Context:  :\n",
      "\n",
      " Tauã is passionate about using technology to support business goals\n",
      "\n",
      "###\n",
      "\n",
      " Tauã holds certifications in Analytics Engineering Associate, Generative AI Associate, and Data Science Associate from Itaú\n",
      "\n",
      "###\n",
      "\n",
      " Tauã is fluent in English, which allows him to collaborate effectively with international teams and stakeholders\n",
      "\n",
      "###\n",
      "\n",
      " Beyond his professional experience, Tauã has pursued additional education in business, covering financial analysis, valuation, marketing, and strategy\n",
      "\n",
      "###\n",
      "\n",
      "Tauã Santos is a dedicated Mechanical Engineer with experience in data analytics, process automation, and machine learning applications\n",
      "\n",
      "###\n",
      "\n",
      " Through his expertise in automation, machine learning, and data analytics, Tauã strives to make meaningful contributions to his work\n",
      "\n",
      "###\n",
      "\n",
      " Beyond his technical skills, Tauã believes in the importance of strategic decision-making supported by data\n",
      "\n",
      "###\n",
      "\n",
      " Currently, as a Product Analyst, Tauã is part of an onboarding squad at Itaú, helping establish key performance indicators (KPIs)\n",
      "\n",
      "###\n",
      "\n",
      " Throughout his career, Tauã has maintained a strong commitment to continuous learning and professional growth\n",
      "\n",
      "###\n",
      "\n",
      " Tauã has experience with internal bank databases, including those related to customer accreditation, settlement, account opening, and credit risk assessment\n",
      "\n",
      "###\n",
      "\n",
      " As he advances in his career, Tauã remains dedicated to learning and applying emerging technologies\n",
      "\n",
      "###\n",
      "\n",
      " With a strong foundation in engineering and a keen interest in data analytics, Tauã continues to seek opportunities to apply his knowledge in practical ways\n",
      "\n",
      "###\n",
      "\n",
      " During his tenure at Itaú, Tauã began as an intern, contributing to process automation efforts using Python and SQL\n",
      "\n",
      "###\n",
      "\n",
      " He has participated in projects and competitions, including the Itaú Data Battle in 2022, where he developed a classification model\n",
      "\n",
      "###\n",
      "\n",
      " He graduated from the Polytechnic School of the University of São Paulo and has developed expertise in Python, SQL, AWS services, and data engineering practices\n",
      "\n",
      "---\n",
      "\n",
      "Question: who is Taua?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(\"who is Taua?\", df, 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Retrieve Answers from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=3000, max_answer_tokens=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens,\n",
    "            temperature = 0\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Question: who is Taua?\n",
      "\n",
      "    Original Answer: Taua does not appear to be a known person. It could be a name or a term used in a specific context or language. Without more information, it is impossible to determine who Taua is.\n",
      "    Custom Answer:   Tauã is a dedicated Mechanical Engineer with experience in data analytics, process automation, and machine learning applications.\n",
      "    \n",
      "\n",
      "    Question: where Taua graduated?\n",
      "\n",
      "    Original Answer: I'm sorry, I do not have information about Taua's educational background.\n",
      "    Custom Answer:   Polytechnic School of the University of São Paulo\n",
      "    \n",
      "Exiting.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Type your question (or 'exit' to exit): \").strip()\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Exiting.\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        initial_who_is_answer = openai.Completion.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=f\"Question: {user_input}\\nAnswer:\",\n",
    "            max_tokens=150\n",
    "        )[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        initial_who_is_answer = f\"Error: {e}\"\n",
    "\n",
    "    custom_who_is_answer = answer_question(user_input, df)\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Question: {user_input}\n",
    "\n",
    "    Original Answer: {initial_who_is_answer}\n",
    "    Custom Answer:   {custom_who_is_answer}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the customized model demonstrates excellent performance by accurately answering both questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
